{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowlegde graphs GenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=visualisation.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Common data processing\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "# Langchain\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE') or 'neo4j'\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Neo4j\n",
    "\n",
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "\n",
    "def get_llm():\n",
    "    load_dotenv('.env', override=True)\n",
    "    return AzureChatOpenAI(azure_deployment=\"gpt-4o-mini\", api_version=\"2024-08-01-preview\")\n",
    "\n",
    "def get_embedding():\n",
    "    load_dotenv('.env', override=True)\n",
    "    return AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-ada-002\", api_version=\"2023-05-15\")\n",
    "\n",
    "embedding_model = get_embedding()\n",
    "llm_model = get_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_loader(file_path: str):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    text = \"\"\n",
    "    for page in loader.load():\n",
    "        text += page.page_content\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract metadata for Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xmltodict\n",
    "from time import sleep\n",
    "\n",
    "url = \"https://www.boe.es/datosabiertos/api/boe/sumario/20240101\"\n",
    "\n",
    "\n",
    "def remove_duplicated_from_list_dict(dict_list):\n",
    "    unique_list = []\n",
    "    for d in dict_list:\n",
    "        if d not in unique_list:\n",
    "            unique_list.append(d)\n",
    "    return unique_list\n",
    "\n",
    "\n",
    "def get_items(departament):\n",
    "        if type(departament[\"epigrafe\"]) == dict:\n",
    "            if type(departament[\"epigrafe\"][\"item\"]) == list:\n",
    "                for item in departament[\"epigrafe\"][\"item\"]:\n",
    "                    yield item, departament[\"epigrafe\"][\"@nombre\"], departament[\"@nombre\"]\n",
    "            else:\n",
    "                yield departament[\"epigrafe\"][\"item\"], departament[\"epigrafe\"][\"@nombre\"], departament[\"@nombre\"]\n",
    "        else:\n",
    "            for epigraf in departament[\"epigrafe\"]:\n",
    "                if type(epigraf[\"item\"]) == list:\n",
    "                    for item in epigraf[\"item\"]:\n",
    "                        yield item, epigraf[\"@nombre\"], departament[\"@nombre\"]\n",
    "                else:\n",
    "                    yield epigraf[\"item\"], epigraf[\"@nombre\"], departament[\"@nombre\"]\n",
    "\n",
    "\n",
    "def get_metadata(url: str):\n",
    "    headers = {\"Accept\": \"application/xml\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data_dict = xmltodict.parse(response.content)\n",
    "        chunks_with_metadata = []\n",
    "        items_with_metadata = []\n",
    "        epigraf_with_metadata = []\n",
    "        department_with_metadata = []\n",
    "        seccion_with_metadata = []\n",
    "        sumario_with_metadata = []\n",
    "        sumario = data_dict[\"response\"][\"data\"][\"sumario\"][\"diario\"][\"sumario_diario\"]\n",
    "        sumario_with_metadata.append({\"sumario_id\": sumario[\"identificador\"], \"source\": sumario[\"url_pdf\"][\"#text\"]})\n",
    "        for seccion in data_dict[\"response\"][\"data\"][\"sumario\"][\"diario\"][\"seccion\"]:\n",
    "            seccion_with_metadata.append({'seccion_id': seccion[\"@nombre\"], \"sumario_id\": sumario[\"identificador\"]})\n",
    "            for departament in seccion[\"departamento\"]:\n",
    "                department_with_metadata.append({'department_id': departament[\"@nombre\"], 'seccion_id': seccion[\"@nombre\"], \"sumario_id\": sumario[\"identificador\"]})\n",
    "                for item, epigraf, department in get_items(departament):\n",
    "                    epigraf_with_metadata.append({'epigraf_id': epigraf, 'department_id': department, 'seccion_id': seccion[\"@nombre\"], \"sumario_id\": sumario[\"identificador\"]})\n",
    "                    items_with_metadata.append(\n",
    "                        {\n",
    "                            'title': item[\"titulo\"],\n",
    "                            'item_id': item[\"identificador\"],\n",
    "                            'epigraf_id': epigraf,\n",
    "                            'department_id': department,\n",
    "                            'seccion_id': seccion[\"@nombre\"],\n",
    "                            'sumario_id': sumario[\"identificador\"],\n",
    "                            'control': item[\"control\"],\n",
    "                            'source': item[\"url_pdf\"][\"#text\"]\n",
    "                        }\n",
    "                    )\n",
    "                    item_text = pdf_loader(file_path=f\"C:/Users/2373225/projects/genai-1/data/pdfs/{item['identificador']}.pdf\")\n",
    "                    item_text_chunks = text_splitter.split_text(item_text)\n",
    "                    chunk_seq_id = 0\n",
    "                    for chunk in item_text_chunks:\n",
    "                        chunks_with_metadata.append(\n",
    "                            {\n",
    "                                'text': chunk,\n",
    "                                'chunk_id': f\"{item['identificador']}-chunk{chunk_seq_id:04d}\",\n",
    "                                'item_id': item[\"identificador\"],\n",
    "                                'epigraf_id': epigraf,\n",
    "                                'department_id': department,\n",
    "                                'seccion_id': seccion[\"@nombre\"],\n",
    "                                'sumario_id': sumario[\"identificador\"],\n",
    "                                'chunkSeqId': chunk_seq_id,\n",
    "                                'source': item[\"url_pdf\"][\"#text\"]\n",
    "                            }\n",
    "                        )\n",
    "                        chunk_seq_id += 1\n",
    "\n",
    "    return (remove_duplicated_from_list_dict(chunks_with_metadata), \n",
    "           remove_duplicated_from_list_dict(items_with_metadata), \n",
    "           remove_duplicated_from_list_dict(epigraf_with_metadata), \n",
    "           remove_duplicated_from_list_dict(department_with_metadata), \n",
    "           remove_duplicated_from_list_dict(seccion_with_metadata), \n",
    "           remove_duplicated_from_list_dict(sumario_with_metadata))\n",
    "\n",
    "\n",
    "chunks_metadata, items_metadata, epigraf_metadata, department_metadata, seccion_metadata, sumario_metadata = get_metadata(url=url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create all nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Chunk nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_chunk_node_query = \"\"\"\n",
    "MERGE(mergedChunk:Chunk {chunk_id: $chunkParam.chunk_id})\n",
    "    ON CREATE SET \n",
    "        mergedChunk.text = $chunkParam.text,\n",
    "        mergedChunk.item_id = $chunkParam.item_id,\n",
    "        mergedChunk.epigraf_id = $chunkParam.epigraf_id,\n",
    "        mergedChunk.department_id = $chunkParam.epigraf_id,\n",
    "        mergedChunk.seccion_id = $chunkParam.seccion_id,\n",
    "        mergedChunk.sumario_id = $chunkParam.sumario_id,\n",
    "        mergedChunk.source = $chunkParam.source, \n",
    "        mergedChunk.chunkSeqId = $chunkParam.chunkSeqId\n",
    "        \n",
    "RETURN mergedChunk\n",
    "\"\"\"\n",
    "\n",
    "kg.query(merge_chunk_node_query, params={'chunkParam': chunks_metadata[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "CREATE CONSTRAINT unique_chunk IF NOT EXISTS \n",
    "    FOR (c:Chunk) REQUIRE c.chunk_id IS UNIQUE\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count = 0\n",
    "for chunk in chunks_metadata:\n",
    "    print(f\"Creating `:Chunk` node for chunk ID {chunk['chunk_id']}\")\n",
    "    kg.query(merge_chunk_node_query, \n",
    "            params={\n",
    "                'chunkParam': chunk\n",
    "            })\n",
    "    node_count += 1\n",
    "print(f\"Created {node_count} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Item nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "CREATE CONSTRAINT unique_item IF NOT EXISTS \n",
    "    FOR (i:Item) REQUIRE i.item_id IS UNIQUE\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_item_node_query = \"\"\"\n",
    "MERGE(mergedItem:Item {item_id:$ItemParam.item_id})\n",
    "    ON CREATE SET \n",
    "        mergedItem.title = $ItemParam.title,\n",
    "        mergedItem.item_id = $ItemParam.item_id,\n",
    "        mergedItem.epigraf_id = $ItemParam.epigraf_id,\n",
    "        mergedItem.department_id = $ItemParam.department_id,\n",
    "        mergedItem.seccion_id = $ItemParam.seccion_id,\n",
    "        mergedItem.sumario_id = $ItemParam.sumario_id,\n",
    "        mergedItem.control = $ItemParam.control,\n",
    "        mergedItem.source = $ItemParam.source\n",
    "RETURN mergedItem\n",
    "\"\"\"\n",
    "\n",
    "node_count = 0\n",
    "for item in items_metadata:\n",
    "    print(f\"Creating `:Item` node for item_id {item['item_id']}\")\n",
    "    kg.query(merge_item_node_query, \n",
    "            params={\n",
    "                'ItemParam': item\n",
    "            })\n",
    "    node_count += 1\n",
    "print(f\"Created {node_count} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "         CREATE VECTOR INDEX `item_chunks` IF NOT EXISTS\n",
    "          FOR (c:Chunk) ON (c.textEmbedding) \n",
    "          OPTIONS { indexConfig: {\n",
    "            `vector.dimensions`: 1536,\n",
    "            `vector.similarity_function`: 'cosine'    \n",
    "         }}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "         CREATE VECTOR INDEX `item_titles` IF NOT EXISTS\n",
    "          FOR (i:Item) ON (i.titleEmbedding) \n",
    "          OPTIONS { indexConfig: {\n",
    "            `vector.dimensions`: 1536,\n",
    "            `vector.similarity_function`: 'cosine'    \n",
    "         }}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed text of chunk nodes and title of item nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "# Total chunks to embed\n",
    "total_nodes_to_embed = kg.query(\"\"\"\n",
    "    MATCH (chunk:Chunk)\n",
    "    RETURN count(chunk) AS TotalChunksToEmbed\n",
    "\"\"\")\n",
    "\n",
    "# Function to get the number of nodes pending to embed\n",
    "def pending_nodes_to_emded():\n",
    "    number_embedded_nodes = kg.query(\n",
    "      \"\"\"\n",
    "      MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL \n",
    "      RETURN count(chunk) AS NotEmbedChunks                          \n",
    "      \"\"\"\n",
    "    )\n",
    "    return number_embedded_nodes[0][\"NotEmbedChunks\"]\n",
    "\n",
    "# Initialize pending_nodes variable\n",
    "pending_nodes = pending_nodes_to_emded()\n",
    "\n",
    "while pending_nodes != 0:\n",
    "  try:\n",
    "    print(\"Embedding nodes...\")\n",
    "    kg.query(\"\"\"\n",
    "        MATCH (chunk:Chunk WHERE chunk.textEmbedding IS NULL)\n",
    "        WITH chunk\n",
    "        LIMIT $embedding_batch_size\n",
    "        WITH chunk, genai.vector.encode(\n",
    "          chunk.text, \n",
    "          \"AzureOpenAI\", \n",
    "          {\n",
    "            token: $openAiApiKey,\n",
    "            resource: \"knowledge-graphs\",\n",
    "            deployment: \"text-embedding-ada-002\"\n",
    "          }) AS vector\n",
    "        CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
    "        \"\"\", \n",
    "        params={\"openAiApiKey\": OPENAI_API_KEY, \"embedding_batch_size\": 50} \n",
    "        )\n",
    "    \n",
    "    pending_nodes = pending_nodes_to_emded()\n",
    "    print(f\"Number of pending nodes to embed: {pending_nodes}\")\n",
    "    sleep(60)\n",
    "  except:\n",
    "    print(\"Embedding has reach the limit rate per minut\")\n",
    "    sleep(60)\n",
    "    continue\n",
    "\n",
    "print(\"All nodes have been embeded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_nodes_to_embed = kg.query(\"\"\"\n",
    "    MATCH (item:Item)\n",
    "    RETURN count(item) AS TotalItemsToEmbed\n",
    "\"\"\")\n",
    "\n",
    "# Function to get the number of nodes pending to embed\n",
    "def pending_nodes_to_emded():\n",
    "    number_embedded_nodes = kg.query(\n",
    "      \"\"\"\n",
    "      MATCH (item:Item) WHERE item.titleEmbedding IS NULL \n",
    "      RETURN count(item) AS NotEmbedItems                          \n",
    "      \"\"\"\n",
    "    )\n",
    "    return number_embedded_nodes[0][\"NotEmbedItems\"]\n",
    "\n",
    "# Initialize pending_nodes variable\n",
    "pending_nodes = pending_nodes_to_emded()\n",
    "\n",
    "while pending_nodes != 0:\n",
    "  try:\n",
    "    print(\"Embedding nodes...\")\n",
    "    kg.query(\"\"\"\n",
    "        MATCH (item:Item WHERE item.titleEmbedding IS NULL)\n",
    "        WITH item\n",
    "        LIMIT $embedding_batch_size\n",
    "        WITH item, genai.vector.encode(\n",
    "          item.title, \n",
    "          \"AzureOpenAI\", \n",
    "          {\n",
    "            token: $openAiApiKey,\n",
    "            resource: \"knowledge-graphs\",\n",
    "            deployment: \"text-embedding-ada-002\"\n",
    "          }) AS vector\n",
    "        CALL db.create.setNodeVectorProperty(item, \"titleEmbedding\", vector)\n",
    "        \"\"\", \n",
    "        params={\"openAiApiKey\": OPENAI_API_KEY, \"embedding_batch_size\": 50} \n",
    "        )\n",
    "    \n",
    "    pending_nodes = pending_nodes_to_emded()\n",
    "    print(f\"Number of pending nodes to embed: {pending_nodes}\")\n",
    "    if pending_nodes != 0:\n",
    "        sleep(60)\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    sleep(60)\n",
    "    continue\n",
    "\n",
    "print(\"All nodes have been embeded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use similarity search to find relevant chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neo4j_vector_search(question):\n",
    "  \"\"\"Search for similar nodes using the Neo4j vector index\"\"\"\n",
    "  vector_search_query = \"\"\"\n",
    "    WITH genai.vector.encode(\n",
    "      $question, \n",
    "      \"AzureOpenAI\", \n",
    "      {\n",
    "        token: $openAiApiKey,\n",
    "        resource: \"knowledge-graphs\",\n",
    "        deployment: \"text-embedding-ada-002\"\n",
    "      }) AS question_embedding\n",
    "    CALL db.index.vector.queryNodes($index_name, $top_k, question_embedding) yield node, score\n",
    "    RETURN score, node.title AS title, node.item_id AS boe_id\n",
    "  \"\"\"\n",
    "  similar = kg.query(vector_search_query, \n",
    "                     params={\n",
    "                      'question': question, \n",
    "                      'openAiApiKey':OPENAI_API_KEY,\n",
    "                      'index_name': \"item_titles\", \n",
    "                      'top_k': 10})\n",
    "  return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = neo4j_vector_search('Quiero información sobre la Resolución 1A0/38511/2023')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG without connections. It's the same as standard RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_vector_store = Neo4jVector.from_existing_index(\n",
    "    embedding=embedding_model,\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    index_name=\"item_chunks\",\n",
    "    node_label=\"Chunk\",\n",
    "    text_node_property=\"text\",\n",
    "    embedding_node_property=\"textEmbedding\"\n",
    ")\n",
    "\n",
    "retriever = neo4j_vector_store.as_retriever(search_kwargs={'k': 5})\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm_model, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create connections between items and chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. NEXT connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(86):\n",
    "  cypher = \"\"\"\n",
    "    MATCH (from_same_item:Chunk)\n",
    "      WHERE from_same_item.item_id = $ItemIdParam\n",
    "    WITH from_same_item\n",
    "      ORDER BY from_same_item.chunkSeqId ASC\n",
    "    WITH collect(from_same_item) as item_chunk_list\n",
    "      CALL apoc.nodes.link(\n",
    "        item_chunk_list,\n",
    "        \"NEXT\",\n",
    "        {avoidDuplicates: true}\n",
    "      )\n",
    "    RETURN size(item_chunk_list)\n",
    "  \"\"\"\n",
    "\n",
    "  kg.query(cypher, params={'ItemIdParam': items_metadata[i]['item_id']})\n",
    "\n",
    "  print(f\"NEXT connections from chunks of item_id {items_metadata[i]['item_id']} created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PART_OF connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (c:Chunk), (i:Item)\n",
    "    WHERE c.item_id = i.item_id\n",
    "  MERGE (c)-[newRelationship:PART_OF]->(i)\n",
    "  RETURN count(newRelationship)\n",
    "\"\"\"\n",
    "\n",
    "kg.query(cypher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SECTION connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (first:Chunk), (i:Item)\n",
    "  WHERE first.item_id = i.item_id\n",
    "    AND first.chunkSeqId = 0\n",
    "  WITH first, i\n",
    "    MERGE (i)-[r:SECTION]->(first)\n",
    "  RETURN count(r)\n",
    "\"\"\"\n",
    "\n",
    "kg.query(cypher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG with connections and window retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_query_window = \"\"\"\n",
    "MATCH window=\n",
    "    (:Chunk)-[:NEXT*0..2]->(node)-[:NEXT*0..2]->(:Chunk)\n",
    "WITH node, score, window as longestWindow \n",
    "  ORDER BY length(window) DESC LIMIT 1\n",
    "WITH nodes(longestWindow) as chunkList, node, score\n",
    "  UNWIND chunkList as chunkRows\n",
    "WITH collect(chunkRows.text) as textList, node, score\n",
    "RETURN apoc.text.join(textList, \" \\n \") as text,\n",
    "    score,\n",
    "    node {.source} AS metadata\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_window = Neo4jVector.from_existing_index(\n",
    "    embedding=embedding_model,\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    index_name=\"item_chunks\",\n",
    "    node_label=\"Chunk\",\n",
    "    text_node_property=\"text\",\n",
    "    retrieval_query=retrieval_query_window\n",
    ")\n",
    "\n",
    "# Create a retriever from the vector store\n",
    "retriever_window = vector_store_window.as_retriever(search_kwargs={'k': 1})\n",
    "\n",
    "# Create a chatbot Question & Answer chain from the retriever\n",
    "chain_window = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm_model, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever_window\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "def rich_output(response):\n",
    "    console = Console()\n",
    "    md = Markdown(response)\n",
    "    console.print(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_comparison(question):\n",
    "    response_a = chain({\"question\": question}, return_only_outputs=True,)\n",
    "    response_b = chain_window({\"question\": question}, return_only_outputs=True,)    \n",
    "\n",
    "    response_rag = ''\n",
    "    response_rag += 'Response with standard RAG pipeline\\n'\n",
    "    response_rag += '-----------------------------------\\n'\n",
    "    response_rag += response_a[\"answer\"]\n",
    "\n",
    "    rich_output(response_rag)\n",
    "\n",
    "    response_graphrag = ''\n",
    "    response_graphrag += 'Response with GRAPH-RAG pipeline\\n'\n",
    "    response_graphrag += '-----------------------------------\\n'\n",
    "    response_graphrag += response_b[\"answer\"]\n",
    "\n",
    "    rich_output(response_graphrag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Ask questions contained in the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a question\n",
    "question = \"Quiero información sobre la Resolución 1A0/38511/2023\"\n",
    "\n",
    "print_comparison(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                        <span style=\"font-weight: bold; text-decoration: underline\">Response with standard RAG pipeline</span>                                        \n",
       "\n",
       "La Resolución 1A0/38511/2023, de 15 de noviembre, del Centro Criptológico Nacional certifica la seguridad del      \n",
       "producto «TC-FNMT versión 5.6», solicitado por la Fábrica Nacional de Moneda y Timbre-Real Casa de la Moneda. Esta \n",
       "certificación se basa en la evaluación de seguridad conforme a las normas establecidas y garantiza que el producto \n",
       "cumple con los requisitos necesarios para su certificación. La resolución también establece que el informe de      \n",
       "certificación y la declaración de seguridad están disponibles para consulta en el Centro Criptológico Nacional.    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                        \u001b[1;4mResponse with standard RAG pipeline\u001b[0m                                        \n",
       "\n",
       "La Resolución 1A0/38511/2023, de 15 de noviembre, del Centro Criptológico Nacional certifica la seguridad del      \n",
       "producto «TC-FNMT versión 5.6», solicitado por la Fábrica Nacional de Moneda y Timbre-Real Casa de la Moneda. Esta \n",
       "certificación se basa en la evaluación de seguridad conforme a las normas establecidas y garantiza que el producto \n",
       "cumple con los requisitos necesarios para su certificación. La resolución también establece que el informe de      \n",
       "certificación y la declaración de seguridad están disponibles para consulta en el Centro Criptológico Nacional.    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                          <span style=\"font-weight: bold; text-decoration: underline\">Response with GRAPHRAG pipeline</span>                                          \n",
       "\n",
       "La Resolución 1A0/38511/2023, de 15 de noviembre, del Centro Criptológico Nacional certifica la seguridad del      \n",
       "producto \"TC-FNMT versión 5.6\", solicitado por la Fábrica Nacional de Moneda y Timbre-Real Casa de la Moneda. Esta \n",
       "certificación se basa en el cumplimiento de las propiedades de seguridad especificadas en la Declaración de        \n",
       "Seguridad del producto y en el Informe Técnico de Evaluación de Applus Laboratories. La certificación asegura que  \n",
       "el producto cumple con las normas requeridas y tiene un nivel de garantía de evaluación EAL4, entre otros.         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                          \u001b[1;4mResponse with GRAPHRAG pipeline\u001b[0m                                          \n",
       "\n",
       "La Resolución 1A0/38511/2023, de 15 de noviembre, del Centro Criptológico Nacional certifica la seguridad del      \n",
       "producto \"TC-FNMT versión 5.6\", solicitado por la Fábrica Nacional de Moneda y Timbre-Real Casa de la Moneda. Esta \n",
       "certificación se basa en el cumplimiento de las propiedades de seguridad especificadas en la Declaración de        \n",
       "Seguridad del producto y en el Informe Técnico de Evaluación de Applus Laboratories. La certificación asegura que  \n",
       "el producto cumple con las normas requeridas y tiene un nivel de garantía de evaluación EAL4, entre otros.         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a question\n",
    "question = \"Quiero información sobre la Resolución 1A0/38511/2023, de 15 de noviembre, del Centro Criptológico Nacional\"\n",
    "\n",
    "print_comparison(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                        <span style=\"font-weight: bold; text-decoration: underline\">Response with standard RAG pipeline</span>                                        \n",
       "\n",
       "No tengo información suficiente sobre la Resolución 1A0/38511/2023, de 15 de noviembre, del Centro Criptológico    \n",
       "Nacional para proporcionar los 5 puntos solicitados.                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                        \u001b[1;4mResponse with standard RAG pipeline\u001b[0m                                        \n",
       "\n",
       "No tengo información suficiente sobre la Resolución 1A0/38511/2023, de 15 de noviembre, del Centro Criptológico    \n",
       "Nacional para proporcionar los 5 puntos solicitados.                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                          <span style=\"font-weight: bold; text-decoration: underline\">Response with GRAPHRAG pipeline</span>                                          \n",
       "\n",
       "No tengo información sobre los 5 puntos de la Resolución 1A0/38511/2023, de 15 de noviembre, del Centro            \n",
       "Criptológico Nacional.                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                          \u001b[1;4mResponse with GRAPHRAG pipeline\u001b[0m                                          \n",
       "\n",
       "No tengo información sobre los 5 puntos de la Resolución 1A0/38511/2023, de 15 de noviembre, del Centro            \n",
       "Criptológico Nacional.                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a question\n",
    "question = \"Indica y explica los 5 puntos sobre la Resolución 1A0/38511/2023, de 15 de noviembre, del Centro Criptológico Nacional\"\n",
    "\n",
    "print_comparison(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve chunks creating a window from the item title and getting chunk context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_query_window_for_item_title = \"\"\"\n",
    "MATCH window=\n",
    "    (node)-[:SECTION*0..1]->(:Chunk)-[:NEXT*0..1]->(:Chunk)\n",
    "WITH node, score, window as longestWindow \n",
    "  ORDER BY length(window) DESC LIMIT 6\n",
    "WITH nodes(longestWindow) as itemList, node, score\n",
    "  UNWIND itemList as itemRows\n",
    "WITH collect(itemRows.text) as textList, node, score\n",
    "RETURN apoc.text.join(textList, \" \\n \") as text, score, node {.source} AS metadata\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_window_for_item_title = Neo4jVector.from_existing_index(\n",
    "    embedding=embedding_model,\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    database=\"neo4j\",\n",
    "    index_name=\"item_titles\",\n",
    "    text_node_property=\"title\",\n",
    "    retrieval_query=retrieval_query_window_for_item_title\n",
    ")\n",
    "\n",
    "# Create a retriever from the vector store\n",
    "retriever_window_for_item_title = vector_store_window_for_item_title.as_retriever(search_kwargs={'k': 6})\n",
    "\n",
    "# Create a chatbot Question & Answer chain from the retriever\n",
    "chain_window_for_item_title = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm_model, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever_window\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">La Resolución 1A0/38511/2023, de 15 de noviembre, del Centro Criptológico Nacional, aborda los siguientes cinco    \n",
       "puntos clave:                                                                                                      \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Certificación de Seguridad</span>: Se certifica que el producto «TC-FNMT versión 5.6» cumple con lo especificado en su \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>Declaración de Seguridad, garantizando que tiene las propiedades de seguridad necesarias según las normas       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>establecidas.                                                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Informe Técnico de Evaluación</span>: Se ha recibido un informe técnico de evaluación de Applus Laboratories que       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>confirma el cumplimiento del producto con los estándares de seguridad requeridos.                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Cumplimiento Normativo</span>: La certificación se basa en el cumplimiento de los requisitos establecidos por el       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>Reglamento de Evaluación y Certificación de la Seguridad de las Tecnologías de la Información, asegurando que el\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>producto satisface las exigencias legales.                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">Acceso a Documentación</span>: El Informe de Certificación y la Declaración de Seguridad están disponibles para        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>consulta en el Centro Criptológico Nacional, ofreciendo transparencia y acceso a la información sobre la        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>certificación.                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span><span style=\"font-weight: bold\">Entrada en Vigor</span>: La resolución entra en vigor al día siguiente de su publicación en el «Boletín Oficial del    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>Estado», formalizando así su validez y aplicabilidad.                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "La Resolución 1A0/38511/2023, de 15 de noviembre, del Centro Criptológico Nacional, aborda los siguientes cinco    \n",
       "puntos clave:                                                                                                      \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mCertificación de Seguridad\u001b[0m: Se certifica que el producto «TC-FNMT versión 5.6» cumple con lo especificado en su \n",
       "\u001b[1;33m   \u001b[0mDeclaración de Seguridad, garantizando que tiene las propiedades de seguridad necesarias según las normas       \n",
       "\u001b[1;33m   \u001b[0mestablecidas.                                                                                                   \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mInforme Técnico de Evaluación\u001b[0m: Se ha recibido un informe técnico de evaluación de Applus Laboratories que       \n",
       "\u001b[1;33m   \u001b[0mconfirma el cumplimiento del producto con los estándares de seguridad requeridos.                               \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mCumplimiento Normativo\u001b[0m: La certificación se basa en el cumplimiento de los requisitos establecidos por el       \n",
       "\u001b[1;33m   \u001b[0mReglamento de Evaluación y Certificación de la Seguridad de las Tecnologías de la Información, asegurando que el\n",
       "\u001b[1;33m   \u001b[0mproducto satisface las exigencias legales.                                                                      \n",
       "\u001b[1;33m 4 \u001b[0m\u001b[1mAcceso a Documentación\u001b[0m: El Informe de Certificación y la Declaración de Seguridad están disponibles para        \n",
       "\u001b[1;33m   \u001b[0mconsulta en el Centro Criptológico Nacional, ofreciendo transparencia y acceso a la información sobre la        \n",
       "\u001b[1;33m   \u001b[0mcertificación.                                                                                                  \n",
       "\u001b[1;33m 5 \u001b[0m\u001b[1mEntrada en Vigor\u001b[0m: La resolución entra en vigor al día siguiente de su publicación en el «Boletín Oficial del    \n",
       "\u001b[1;33m   \u001b[0mEstado», formalizando así su validez y aplicabilidad.                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_b = chain_window({\"question\": question}, return_only_outputs=True,)   \n",
    "\n",
    "rich_output(response_b[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
